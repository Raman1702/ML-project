{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using Scikit-Learn (sklearn)\n",
    "\n",
    "This is a classification of emails received on a mass distribution group based on subject and hand labelled categories (supervised). The solution includes preprocessing (stopwords removal, lemmatization using nltk), features using count vectorizer and tfidf transformer. The solution is a vanilla implementation that can be used to extend from here to various text classification problems. \n",
    "\n",
    "Things that can be tweaked to improve accuracy...\n",
    "* Add more parameter configurations to GridSearchCV\n",
    "* Increase number of K Folds used with GridSearchCV, default is 3.\n",
    "* Increase the dataset (current dataset is only 500 emails)\n",
    "* The classes in the dataset are skewed with varying proportions, the dataset can either be balanced by oversampling or the weights for each class can be adjusted if the classifier allows.\n",
    "* Try different classifiers or model stacking\n",
    "\n",
    "### Quick Info...\n",
    "\n",
    "* __Dataset__: Dataset is a csv with columns 'Subject' and 'Categroy' (target variable) for about 500 emails. I'm not sharing dataset as it is from real emails taken from my inbox. Replace the dataset with your own dataset that has these two columns.\n",
    "\n",
    "\n",
    "* __Features__: Features matrix is created using a [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), to get a counts matrix of all tokens and [sklearn.feature_extraction.text.TfidfTransformer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer) to normalize the count matrix.\n",
    "\n",
    "\n",
    "* __Classifier__: [sklearn.linear_model.SGDClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "\n",
    "\n",
    "* __Pipeline__ and __GridSearchCV__: [sklearn.pipeline.Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [sklearn.model_selection.GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) are one of the best things in sklearn. Pipelines let you perform a series of steps on data without individually creating objects, handling parameters/return values and data hand off between steps. GridSearchCV helps with parameter tuning. It also performs cross validation with default 3 fold validation. Pipelines and GridSearchCV together reduce a lot of code complexity and improve readability of a solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#Not using stemming as the performance improvement wasn't observed.\n",
    "#from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>3 BHK duplex house available for rent</td>\n",
       "      <td>Real-Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>[Lease Transfer] Hyundai i10 Sportz Car with ...</td>\n",
       "      <td>Automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>Advice about Ooty trip</td>\n",
       "      <td>Travel-Fun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Subject     Category\n",
       "1103  3 BHK duplex house available for rent...  Real-Estate\n",
       "1259  [Lease Transfer] Hyundai i10 Sportz Car with ...   Automobile\n",
       "877   Advice about Ooty trip...  Travel-Fun"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv('emails.csv')\n",
    "em = emails.dropna(axis=0)\n",
    "em.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real-Estate       231\n",
       "Automobile         86\n",
       "Travel-Fun         45\n",
       "Recommendation     43\n",
       "Sale               39\n",
       "Other              19\n",
       "Relocation         16\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "def pre_process_text(textArray):\n",
    "    #If using stemming...\n",
    "    #stemmer = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    processed_text = []\n",
    "    for text in textArray:\n",
    "        words_list = (str(text).lower()).split()\n",
    "        final_words = [wnl.lemmatize(word) for word in words_list if word not in stopwords.words('english')]\n",
    "        #If using stemming...\n",
    "        #final_words = [stemmer.stem(word) for word in words_list if word not in stopwords.words('english')]\n",
    "        final_words_str = str((\" \".join(final_words)))\n",
    "        processed_text.append(final_words_str)\n",
    "    return processed_text\n",
    "\n",
    "em['Subject'] = pre_process_text(em['Subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [ 'Real-Estate', 'Automobile', 'Travel-Fun', 'Recommendation', 'Sale', 'Other', 'Relocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every additional parameter value here will increase the training time by orders of magnitude. \n",
    "# I'm running on a relatively slow computer, hence reduced the values\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 1.0),#0.6, 0.7, 0.8, 0.9, 1.0),\n",
    "    'vect__max_features': (None, 1000, 5000),#2000, 3000, 4000, 5000, 6000, 10000, 20000, 30000, 40000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),#, (1, 3)),  # unigrams or bigrams or trigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.1, 0.01, 0.001),#, 0.0001, 0.00001, 0.000001, 0.0000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__n_iter': (10, 50)#, 100, 200, 300, 400, 500, 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search started\n",
      "---------------------------------------\n",
      "Pipeline: ['vect', 'tfidf', 'clf']\n",
      "Grid Search Parameters:\n",
      "{'clf__alpha': (0.1, 0.01, 0.001),\n",
      " 'clf__n_iter': (10, 50),\n",
      " 'clf__penalty': ('l2', 'elasticnet'),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 1.0),\n",
      " 'vect__max_features': (None, 1000, 5000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1656 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed:   39.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 40.082s\n",
      "----------------------------------------------\n",
      "Best Score: 0.898\n",
      "-------------------------------------------\n",
      "Best Parameters:\n",
      "\tclf__alpha: 0.001\n",
      "\tclf__n_iter: 50\n",
      "\tclf__penalty: 'l2'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 1000\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, refit=True)\n",
    "\n",
    "print(\"Grid Search started\\n---------------------------------------\")\n",
    "print(\"Pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"Grid Search Parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(np.array(em['Subject']), np.array(em['Category']))\n",
    "print(\"done in %0.3fs\\n----------------------------------------------\" % (time() - t0))\n",
    "\n",
    "print(\"Best Score: %0.3f\\n-------------------------------------------\" % grid_search.best_score_)\n",
    "print(\"Best Parameters:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = [\n",
    "    'RE: items for sale',\n",
    "    'Coorg trip advice',\n",
    "    'movie tickets for sale',\n",
    "    'Advice needed for treatment of hair fall',\n",
    "    'Moving out sale',\n",
    "    'RE: Selling Honda City'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sale', 'Travel-Fun', 'Travel-Fun', 'Recommendation', 'Relocation',\n",
       "       'Automobile'], \n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.predict(np.array(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
